{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100percentiles_1+24.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVLtDkuSxj8q",
        "colab_type": "code",
        "outputId": "3c3c919b-f5f6-4085-b92d-53a61e836272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_J8_ZqZx_cV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j_u8wWdyBTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/thesis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZuHXCSeyFme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_pickle('master_dataset_24112019.pkl')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdOWzeHpyTXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = pd.DataFrame()\n",
        "target['1_h'] = data['dk2'].shift(-1)\n",
        "target['24_h'] = data['dk2'].shift(-24)\n",
        "features = data.iloc[0: -24, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifc5JQ0hyahh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = target[:-24]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsa7kf1ky0te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_fitter = target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIIoq9AlzIlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_mean2 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqtt9v3MzNlC",
        "colab_type": "code",
        "outputId": "84b90378-9731-4de6-927f-4b43aa1add05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "imp_mean2.fit(target_fitter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
              "              missing_values=nan, strategy='most_frequent', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obPfT2kJzPcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_target = imp_mean2.transform(target_fitter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMy26ufPzRq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qs = [-100]\n",
        "for i in range(1, 101):\n",
        "  q = i\n",
        "  qs.append(np.percentile(imp_target, q))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTqeC1bezT2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_feature = features['dk2'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWxD5rp_zVhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_feature = pd.DataFrame(new_feature, index=target.index)\n",
        "new_feature.columns = ['price']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E87H1BZEzldP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_in_range(x, lower, upper, val):\n",
        "  if lower < x <= upper:\n",
        "    return val\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V-TZduSzpsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_in_range(x, lower, upper, val):\n",
        "  if lower < x <= upper:\n",
        "    return val\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DQpoO05zrfU",
        "colab_type": "code",
        "outputId": "c696bde7-03b9-4de7-cc04-459673796577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ss = dict()\n",
        "for i, (lower, upper) in enumerate(zip(qs[:-1], qs[1:])):\n",
        "  print(lower, upper)\n",
        "  s = new_feature['price'].apply(lambda row: is_in_range(row, lower, upper, i))\n",
        "  ss[i] = s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-100 23.524999999999995\n",
            "23.524999999999995 57.2\n",
            "57.2 72.60899999999997\n",
            "72.60899999999997 84.75\n",
            "84.75 97.36499999999998\n",
            "97.36499999999998 111.72\n",
            "111.72 122.9435\n",
            "122.9435 133.65\n",
            "133.65 141.76349999999996\n",
            "141.76349999999996 148.17\n",
            "148.17 152.6155\n",
            "152.6155 157.26\n",
            "157.26 161.58650000000003\n",
            "161.58650000000003 165.27\n",
            "165.27 169.20749999999998\n",
            "169.20749999999998 173.26\n",
            "173.26 176.8\n",
            "176.8 179.71\n",
            "179.71 182.82950000000002\n",
            "182.82950000000002 185.62\n",
            "185.62 187.79\n",
            "187.79 190.72199999999998\n",
            "190.72199999999998 193.65\n",
            "193.65 196.21000000000004\n",
            "196.21000000000004 199.26\n",
            "199.26 201.71300000000002\n",
            "201.71300000000002 204.7\n",
            "204.7 207.45\n",
            "207.45 209.53\n",
            "209.53 211.86\n",
            "211.86 214.13\n",
            "214.13 216.036\n",
            "216.036 217.85\n",
            "217.85 219.73\n",
            "219.73 221.54\n",
            "221.54 223.22999999999996\n",
            "223.22999999999996 224.68\n",
            "224.68 226.45\n",
            "226.45 228.38\n",
            "228.38 230.04\n",
            "230.04 231.54049999999992\n",
            "231.54049999999992 233.53\n",
            "233.53 235.31\n",
            "235.31 237.26\n",
            "237.26 238.83\n",
            "238.83 240.57\n",
            "240.57 242.58000000000004\n",
            "242.58000000000004 244.63\n",
            "244.63 246.25\n",
            "246.25 248.39\n",
            "248.39 250.71\n",
            "250.71 252.96600000000007\n",
            "252.96600000000007 255.16000000000003\n",
            "255.16000000000003 257.87\n",
            "257.87 260.38\n",
            "260.38 262.348\n",
            "262.348 265.1\n",
            "265.1 267.73\n",
            "267.73 269.93\n",
            "269.93 272.76\n",
            "272.76 275.43\n",
            "275.43 277.81\n",
            "277.81 280.63\n",
            "280.63 283.14\n",
            "283.14 285.69\n",
            "285.69 288.653\n",
            "288.653 291.0435000000001\n",
            "291.0435000000001 294.05\n",
            "294.05 297.12\n",
            "297.12 299.475\n",
            "299.475 302.7454999999999\n",
            "302.7454999999999 305.81\n",
            "305.81 309.1765\n",
            "309.1765 312.59\n",
            "312.59 315.87\n",
            "315.87 319.898\n",
            "319.898 323.73\n",
            "323.73 327.53999999999996\n",
            "327.53999999999996 331.23\n",
            "331.23 335.28\n",
            "335.28 339.64\n",
            "339.64 344.1509999999999\n",
            "344.1509999999999 349.65\n",
            "349.65 354.972\n",
            "354.972 359.48\n",
            "359.48 365.56\n",
            "365.56 371.68\n",
            "371.68 377.03\n",
            "377.03 384.1389999999999\n",
            "384.1389999999999 391.445\n",
            "391.445 398.07\n",
            "398.07 407.23\n",
            "407.23 416.63\n",
            "416.63 429.07000000000005\n",
            "429.07000000000005 444.43\n",
            "444.43 461.78\n",
            "461.78 485.47650000000056\n",
            "485.47650000000056 518.02\n",
            "518.02 573.2395000000001\n",
            "573.2395000000001 1898.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etntgK8czXOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_df = pd.DataFrame(ss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSh7Vjrz077",
        "colab_type": "code",
        "outputId": "7c8f7d0b-42ae-4c84-fcd9-072a074278e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "features['price_bin'] = _df.sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4F5eXSfz6Ul",
        "colab_type": "code",
        "outputId": "90a54d8e-9c18-4909-d3db-7f38cad167d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "features['price_bin'] = _df.sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwOWS_Up0HpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#features.to_pickle('master_dataset_15112019.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyegmM4a1G2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_mean1 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp_mean1.fit(features)\n",
        "imp_features = imp_mean1.transform(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spysvx221KdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split = 0.9\n",
        "num_train = int(train_split * len(features))\n",
        "num_test = len(features) - num_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1jax9W71NkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = features.iloc[0:num_train , :]\n",
        "x_test = features.iloc[num_train+1: , :]\n",
        "\n",
        "try:\n",
        "  y_train = target.iloc[0:num_train , :]\n",
        "  y_test = target.iloc[num_train+1: , :]\n",
        "except:\n",
        "  y_train = target_fitter[0:num_train]\n",
        "  y_test = target_fitter[num_train+1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41VK33x_1P7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = imp_mean1.transform(x_train)\n",
        "x_test = imp_mean1.transform(x_test)\n",
        "\n",
        "y_train = imp_mean2.transform(y_train)\n",
        "y_test = imp_mean2.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z9IPEmc1SPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_scaler = MinMaxScaler()\n",
        "x_train_scaled = x_scaler.fit_transform(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQIVJhj1UEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_scaled = x_scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EAtGm6C1XGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_scaler = MinMaxScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train)\n",
        "y_test_scaled = y_scaler.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTvToZI21YQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(batch_size, sequence_length):\n",
        "    \"\"\"\n",
        "    Generator function for creating random batches of training data\n",
        "    \"\"\"\n",
        "    \n",
        "    num_x_signals = features.shape[1]\n",
        "    num_y_signals = 2\n",
        "    \n",
        "    # infinite loop\n",
        "    while True:\n",
        "        # Allocate a new array for the batch of input signals\n",
        "        x_shape = (batch_size, sequence_length, num_x_signals)\n",
        "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
        "        \n",
        "        # Allocate a new array for the batch of output signals \n",
        "        y_shape = (batch_size, sequence_length, num_y_signals)\n",
        "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
        "        \n",
        "        # Fill the batch with random sequences of data\n",
        "        for i in range(batch_size):\n",
        "            # Get a random start_index\n",
        "            # This points somewhere in the training data\n",
        "            idx = np.random.randint(num_train - sequence_length)\n",
        "            \n",
        "            # Copy the sequence of data starting from this index\n",
        "            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n",
        "            y_batch[i] = y_train_scaled[idx:idx+sequence_length]\n",
        "            \n",
        "        yield (x_batch, y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc67nL3-1bmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "sequence_length = 24 * 7 * 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuAi5bzW1dKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = batch_generator(batch_size=batch_size, sequence_length=sequence_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnXI7MCE1eif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_batch, y_batch = next(generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ--8qRY1f2y",
        "colab_type": "code",
        "outputId": "b5ef6ad5-1439-4f21-f276-d3878c28f760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_batch.shape ,y_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((256, 1344, 34), (256, 1344, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9joCSyZ1hBD",
        "colab_type": "code",
        "outputId": "5b2cc9af-3563-4edc-e26f-ac6a117fc98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "batch = 0 \n",
        "signal = 0\n",
        "seq = x_batch[batch , : , signal]\n",
        "plt.plot(seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f669f8e0c18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJcce4zH1ifl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = (np.expand_dims(x_test_scaled, axis=0),\n",
        "                   np.expand_dims(y_test_scaled, axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75P0C1HK1kNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'regression_clipped_extremes_pyramid_21112019_1+24'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-45ifC81ob3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=100,\n",
        "               input_shape=(None, x_train.shape[1],),\n",
        "               return_sequences=True,\n",
        "               dropout=0.2,\n",
        "               recurrent_dropout=0.5))\n",
        "model.add(LSTM(units=30,\n",
        "               return_sequences=True,\n",
        "               dropout=0.2,\n",
        "               recurrent_dropout=0.5))\n",
        "model.add(LSTM(units=20,\n",
        "               return_sequences=True,\n",
        "               dropout=0.2,\n",
        "               recurrent_dropout=0.5))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh_brSUt1rvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "warmup_steps = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUanMAnH1xsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_mse_warmup(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the mean squared error between y_true and y_pred but ignores the warmup-period of the sequence,\n",
        "    as there is not yet enough data to make serious predictions.\n",
        "    \"\"\"\n",
        "    \n",
        "    # The shape of both input tensors are \n",
        "    # (batch_size, sequence_length, num_y_signals)\n",
        "    \n",
        "    # Ignore the warm-up period by taking slices of the tensors\n",
        "    y_true_slice = y_true[: , warmup_steps: , :]\n",
        "    y_pred_slice = y_pred[: , warmup_steps: , :]\n",
        "    \n",
        "    # The sliced tensors have the shape (batch_size, sequence_length - warmup_length, num_y_signals)\n",
        "    \n",
        "    # Calculate the MSE loss for each value pair\n",
        "    #loss = tf.losses.mean_squared_error(y_true_slice, y_pred_slice)\n",
        "    #loss = tf.losses.softmax_cross_entropy(y_true_slice, y_pred_slice)\n",
        "    loss = tf.keras.losses.MSLE(y_true_slice, y_pred_slice)\n",
        "    loss_mean = tf.reduce_mean(loss)\n",
        "    \n",
        "    return loss_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIlR78J51z7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = RMSprop(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKao4uzY11rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=loss_mse_warmup, optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F-XE_DI13LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_checkpoint = f'/content/gdrive/My Drive/thesis/{MODEL_NAME}.keras'\n",
        "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
        "                                      monitor='val_loss',\n",
        "                                      verbose=1,\n",
        "                                      save_weights_only=True,\n",
        "                                      save_best_only=True)\n",
        "\n",
        "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                       factor=0.1,\n",
        "                                       min_lr=1e-4,\n",
        "                                       patience=2,\n",
        "                                       verbose=1)\n",
        "\n",
        "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                                        patience=5,\n",
        "                                        verbose=1)\n",
        "\n",
        "callback_tensorboard = TensorBoard(log_dir=f'/content/gdrive/My Drive/thesis/',\n",
        "                                   histogram_freq=0,\n",
        "                                   write_graph=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXvjexfF15Gv",
        "colab_type": "code",
        "outputId": "700bcbea-ecbf-4881-ce2b-a82bb611aa93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(generator=generator,\n",
        "                    epochs=60,\n",
        "                    steps_per_epoch=50,\n",
        "                    validation_data=validation_data,\n",
        "                    callbacks=[callback_checkpoint, callback_reduce_lr, callback_early_stopping, callback_tensorboard])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 0.0079Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 2:15 - loss: 6.6914e-04\n",
            "Epoch 00001: val_loss improved from inf to 0.00067, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 594s 12s/step - loss: 0.0077 - val_loss: 6.6914e-04\n",
            "Epoch 2/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 0.0012Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:43 - loss: 0.0010\n",
            "Epoch 00002: val_loss did not improve from 0.00067\n",
            "50/50 [==============================] - 595s 12s/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 3/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 7.7313e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:44 - loss: 5.9109e-04\n",
            "Epoch 00003: val_loss improved from 0.00067 to 0.00059, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "50/50 [==============================] - 595s 12s/step - loss: 7.7113e-04 - val_loss: 5.9109e-04\n",
            "Epoch 4/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 5.5889e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:44 - loss: 4.2805e-04\n",
            "Epoch 00004: val_loss improved from 0.00059 to 0.00043, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 588s 12s/step - loss: 5.5820e-04 - val_loss: 4.2805e-04\n",
            "Epoch 5/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 5.1339e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:41 - loss: 3.9704e-04\n",
            "Epoch 00005: val_loss improved from 0.00043 to 0.00040, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 587s 12s/step - loss: 5.1350e-04 - val_loss: 3.9704e-04\n",
            "Epoch 6/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 4.7427e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:42 - loss: 3.9687e-04\n",
            "Epoch 00006: val_loss improved from 0.00040 to 0.00040, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "50/50 [==============================] - 584s 12s/step - loss: 4.7383e-04 - val_loss: 3.9687e-04\n",
            "Epoch 7/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 4.4454e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 3.6358e-04\n",
            "Epoch 00007: val_loss improved from 0.00040 to 0.00036, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 592s 12s/step - loss: 4.4373e-04 - val_loss: 3.6358e-04\n",
            "Epoch 8/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 4.1103e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:41 - loss: 3.8167e-04\n",
            "Epoch 00008: val_loss did not improve from 0.00036\n",
            "50/50 [==============================] - 595s 12s/step - loss: 4.1076e-04 - val_loss: 3.8167e-04\n",
            "Epoch 9/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 4.0032e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:43 - loss: 3.4964e-04\n",
            "Epoch 00009: val_loss improved from 0.00036 to 0.00035, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 592s 12s/step - loss: 4.0014e-04 - val_loss: 3.4964e-04\n",
            "Epoch 10/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.8059e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:43 - loss: 3.3845e-04\n",
            "Epoch 00010: val_loss improved from 0.00035 to 0.00034, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 592s 12s/step - loss: 3.8044e-04 - val_loss: 3.3845e-04\n",
            "Epoch 11/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.6576e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:49 - loss: 3.2599e-04\n",
            "Epoch 00011: val_loss improved from 0.00034 to 0.00033, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 591s 12s/step - loss: 3.6526e-04 - val_loss: 3.2599e-04\n",
            "Epoch 12/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.5782e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:48 - loss: 3.1641e-04\n",
            "Epoch 00012: val_loss improved from 0.00033 to 0.00032, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 594s 12s/step - loss: 3.5856e-04 - val_loss: 3.1641e-04\n",
            "Epoch 13/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.4628e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:48 - loss: 3.2338e-04\n",
            "Epoch 00013: val_loss did not improve from 0.00032\n",
            "50/50 [==============================] - 595s 12s/step - loss: 3.4606e-04 - val_loss: 3.2338e-04\n",
            "Epoch 14/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.3852e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:47 - loss: 3.1924e-04\n",
            "Epoch 00014: val_loss did not improve from 0.00032\n",
            "50/50 [==============================] - 590s 12s/step - loss: 3.3922e-04 - val_loss: 3.1924e-04\n",
            "Epoch 15/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.2496e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:50 - loss: 3.1951e-04\n",
            "Epoch 00015: val_loss did not improve from 0.00032\n",
            "50/50 [==============================] - 591s 12s/step - loss: 3.2507e-04 - val_loss: 3.1951e-04\n",
            "Epoch 16/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.1951e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:45 - loss: 3.0921e-04\n",
            "Epoch 00016: val_loss improved from 0.00032 to 0.00031, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 590s 12s/step - loss: 3.1916e-04 - val_loss: 3.0921e-04\n",
            "Epoch 17/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.1131e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 2.9030e-04\n",
            "Epoch 00017: val_loss improved from 0.00031 to 0.00029, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 583s 12s/step - loss: 3.1096e-04 - val_loss: 2.9030e-04\n",
            "Epoch 18/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 3.0384e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 2.8828e-04\n",
            "Epoch 00018: val_loss improved from 0.00029 to 0.00029, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 586s 12s/step - loss: 3.0407e-04 - val_loss: 2.8828e-04\n",
            "Epoch 19/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.9731e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 2.8474e-04\n",
            "Epoch 00019: val_loss improved from 0.00029 to 0.00028, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 582s 12s/step - loss: 2.9706e-04 - val_loss: 2.8474e-04\n",
            "Epoch 20/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.9756e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:45 - loss: 2.8945e-04\n",
            "Epoch 00020: val_loss did not improve from 0.00028\n",
            "50/50 [==============================] - 583s 12s/step - loss: 2.9698e-04 - val_loss: 2.8945e-04\n",
            "Epoch 21/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.8526e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 3.0749e-04\n",
            "Epoch 00021: val_loss did not improve from 0.00028\n",
            "50/50 [==============================] - 585s 12s/step - loss: 2.8540e-04 - val_loss: 3.0749e-04\n",
            "Epoch 22/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.8510e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 2.8726e-04\n",
            "Epoch 00022: val_loss did not improve from 0.00028\n",
            "50/50 [==============================] - 586s 12s/step - loss: 2.8484e-04 - val_loss: 2.8726e-04\n",
            "Epoch 23/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.8108e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 2.8067e-04\n",
            "Epoch 00023: val_loss improved from 0.00028 to 0.00028, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 592s 12s/step - loss: 2.8082e-04 - val_loss: 2.8067e-04\n",
            "Epoch 24/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.7806e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:48 - loss: 2.7577e-04\n",
            "Epoch 00024: val_loss improved from 0.00028 to 0.00028, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 589s 12s/step - loss: 2.7823e-04 - val_loss: 2.7577e-04\n",
            "Epoch 25/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.7210e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:46 - loss: 2.7447e-04\n",
            "Epoch 00025: val_loss improved from 0.00028 to 0.00027, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 590s 12s/step - loss: 2.7235e-04 - val_loss: 2.7447e-04\n",
            "Epoch 26/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.6767e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:45 - loss: 2.6378e-04\n",
            "Epoch 00026: val_loss improved from 0.00027 to 0.00026, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 590s 12s/step - loss: 2.6782e-04 - val_loss: 2.6378e-04\n",
            "Epoch 27/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.6621e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:45 - loss: 2.6649e-04\n",
            "Epoch 00027: val_loss did not improve from 0.00026\n",
            "50/50 [==============================] - 590s 12s/step - loss: 2.6620e-04 - val_loss: 2.6649e-04\n",
            "Epoch 28/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.6558e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:48 - loss: 2.5451e-04\n",
            "Epoch 00028: val_loss improved from 0.00026 to 0.00025, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 588s 12s/step - loss: 2.6608e-04 - val_loss: 2.5451e-04\n",
            "Epoch 29/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.6069e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:51 - loss: 2.5854e-04\n",
            "Epoch 00029: val_loss did not improve from 0.00025\n",
            "50/50 [==============================] - 589s 12s/step - loss: 2.6087e-04 - val_loss: 2.5854e-04\n",
            "Epoch 30/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.6106e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:48 - loss: 2.6165e-04\n",
            "Epoch 00030: val_loss did not improve from 0.00025\n",
            "50/50 [==============================] - 588s 12s/step - loss: 2.6062e-04 - val_loss: 2.6165e-04\n",
            "Epoch 31/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.5762e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:45 - loss: 2.5004e-04\n",
            "Epoch 00031: val_loss improved from 0.00025 to 0.00025, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 587s 12s/step - loss: 2.5764e-04 - val_loss: 2.5004e-04\n",
            "Epoch 32/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.5134e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:47 - loss: 2.4634e-04\n",
            "Epoch 00032: val_loss improved from 0.00025 to 0.00025, saving model to /content/gdrive/My Drive/thesis/regression_clipped_extremes_pyramid_21112019_1+24.keras\n",
            "50/50 [==============================] - 589s 12s/step - loss: 2.5120e-04 - val_loss: 2.4634e-04\n",
            "Epoch 33/60\n",
            "49/50 [============================>.] - ETA: 11s - loss: 2.5315e-04Epoch 1/60\n",
            " 1/50 [..............................] - ETA: 1:53 - loss: 2.5015e-04\n",
            "Epoch 00033: val_loss did not improve from 0.00025\n",
            "50/50 [==============================] - 594s 12s/step - loss: 2.5305e-04 - val_loss: 2.5015e-04\n",
            "Epoch 34/60\n",
            " 9/50 [====>.........................] - ETA: 8:06 - loss: 2.4856e-04"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}